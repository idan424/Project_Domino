{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Feature Extraction & Pickling.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPqHGTFchM0CkO/ptkZNWaw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nFIqrP4PZ4LI","cellView":"form","executionInfo":{"status":"ok","timestamp":1624640731811,"user_tz":-180,"elapsed":270,"user":{"displayName":"עידן לביא","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGX4jNLFmOJ0Uy5vEXtc8TTrQ-ON3TkdZcPQdhPg=s64","userId":"12766125488901089854"}},"outputId":"6f68a325-fa56-44ab-9924-dafcab1b13c8"},"source":["#@title <font color=\"\\#8FBC8F\">Google Drive mount\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M0_HIhqBXEUg","cellView":"form","executionInfo":{"status":"ok","timestamp":1624640740276,"user_tz":-180,"elapsed":8208,"user":{"displayName":"עידן לביא","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGX4jNLFmOJ0Uy5vEXtc8TTrQ-ON3TkdZcPQdhPg=s64","userId":"12766125488901089854"}},"outputId":"e438fd0c-8e88-48ad-c905-872236e46b0b"},"source":["#@title <font color=\"\\#8FBC8F\">Imports\n","\n","import os\n","import pdb\n","from tqdm import tqdm\n","\n","import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","plt.rcParams['figure.figsize'] = [8, 8]\n","plt.rcParams['figure.dpi'] = 100\n","\n","\n","!pip install mne --upgrade --quiet\n","import mne\n","\n","from mne.filter import notch_filter as notch\n","from mne.time_frequency import tfr_morlet as morl\n","from mne.time_frequency import tfr_array_morlet as amorl\n","\n","from mne.decoding import UnsupervisedSpatialFilter\n","from sklearn.decomposition import PCA\n","\n","from sklearn.model_selection import train_test_split as Split\n","\n","print('[imports successfully loaded]')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[imports successfully loaded]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzqcdTtP1EGc","cellView":"form","executionInfo":{"status":"ok","timestamp":1624640740277,"user_tz":-180,"elapsed":24,"user":{"displayName":"עידן לביא","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGX4jNLFmOJ0Uy5vEXtc8TTrQ-ON3TkdZcPQdhPg=s64","userId":"12766125488901089854"}},"outputId":"353172ed-2923-469e-9185-911df662d325"},"source":["#@title <font color=\"\\#8FBC8F\"> Feature Manager Class\n","\n","class WTFeatureManager:\n","    dt = 200#@param {type:'integer'} \n","    sfreq = 250 # [Hz]\n","    f_bands = [0, 4, 8, 13, 30, 60, 80]\n","    f_names = ['Delta', 'Theta', 'Alpha', 'Beta', 'low-Gamma', 'high-Gamma']\n","       \n","    wt_frequencies = np.geomspace(1, 80)\n","    \n","    def __init__(self, data, ch_names=None):\n","        # data is an array - array([epochs, channels, frequencies, time(samles)])\n","        self.data = data\n","        self.n_epochs, self.n_channels, self.n_freq, self.n_samp = data.shape\n","\n","        # channel names will be necesarry for importance retrieval\n","        self.ch_names = ch_names\n","      \n","        # this is the number of samples per bin\n","        self.dsamp = int(self.sfreq*self.dt*1e-3)\n","\n","        # this is an iterator of t0 for each bin\n","        self.t_bins = np.arange(0, self.n_samp, self.dsamp)\n","        \n","        # this is a dict - {'f_band':[wt frequency indices of f_band]}\n","        self.f_idx = self._get_freq_indices()\n","\n","        # number of bins in every wt\n","        self.bins_per_wt = len(self.f_names)*len(self.t_bins)\n","        \n","        # returns bin relevant data & metadata\n","        self.binerator = self._binerator()\n","\n","        # this sets the wt to the first epoch and channel by default, but\n","        # it updates during the\n","        self.wt_bins = self._wt_2d_bin()\n","\n","        # this is a list of tuples - each looks as follows:\n","        # [(epoch_number, channel_index, band_name, time_0_of_bin)]\n","        self.bin_metadata = []\n","        self.bin_features = {}\n","\n","    def _get_freq_indices(self):\n","        \"\"\"\n","        This function returns a dict of indices, where the keys are the \n","        frequency band names, and the values are the ones you'll want to take \n","        from the wavelet transform channel 2D array\n","        \"\"\"\n","        f_idx = {}\n","        for bi,b in enumerate(self.f_bands):\n","            if bi == len(self.f_bands)-1: break\n","            f_idx[self.f_names[bi]] = []\n","            for fi, f in enumerate(self.wt_frequencies):\n","                if b<f<=self.f_bands[bi+1]: f_idx[self.f_names[bi]].append(fi)\n","        return f_idx\n","\n","    def _binerator(self):\n","        \"\"\"\n","        This is a generator that yields bin data and metadata\n","        Will need a reset for each epoch/channel\n","        \"\"\"\n","        for band, i_freq in self.f_idx.items():\n","            for t0 in self.t_bins:\n","                yield (band, i_freq, t0)\n","\n","    def _wt_2d_bin(self, epoch=0, channel=0):\n","        \"\"\"\n","        This is a generator that stores metadata and yields wt_data_bin\n","        doesn't need to be reset for every epoch/channel\n","        \"\"\"\n","        wt = self.data[epoch, channel]\n","        for band, i_f_list, t0 in self.binerator:\n","            self.bin_metadata.append((epoch, channel, \n","                                      band, t0 * self.dt // self.dsamp))\n","            yield wt[i_f_list, t0:t0+self.dsamp]\n","    \n","    # features are declared here as a class variable since they're\n","    # not supposed to change when the right ones are selected\n","    feats = ['min','max','mean','std','median']\n","\n","    def features_from_wt(self):\n","        \"\"\"\n","        This function takes features from the curently selected wt_bins instance\n","        and stores them in the bin_features dict where the metadata for each bin\n","        is the key, and the features are the values\n","\n","        To process a different wt_bins object, you must re initiate the wt_bins \n","        object with correct epoch and channel numbers before running this function\n","        \"\"\"\n","        for bin in self.wt_bins: \n","            md = self.bin_metadata[-1]\n","            self.bin_features[md] = []\n","\n","            # bin is of type np.ndarray\n","            # TODO: uncomment\n","            self.bin_features[md].append(bin.min())\n","            self.bin_features[md].append(bin.max())\n","            self.bin_features[md].append(bin.mean())\n","            self.bin_features[md].append(bin.std())\n","            self.bin_features[md].append(np.median(bin))\n","\n","    def all_ep_ch_feature_extraction(self, norm=False):\n","        \"\"\"\n","        This function will extract all of the features for a subject\n","        \"\"\"\n","        for ep in tqdm(range(self.n_epochs), desc='Epoch:'):\n","\n","            for ch in range(self.n_channels):\n","\n","                self.binerator = self._binerator()\n","                self.wt_bins = self._wt_2d_bin(ep,ch)\n","                self.features_from_wt()\n","    \n","    def as_dataframe(self, norm=False):\n","        self.all_ep_ch_feature_extraction(norm)\n","        \n","        print('[Creating DataFrame]')\n","        df = pd.DataFrame(self.bin_features).T\n","\n","        idx_names = ['Epoch', 'Channel_Number', 'Freq_Band', 'T0 [ms]']\n","        \n","        df.index.set_names(names=idx_names, inplace=True)\n","        \n","        df.rename(columns={k:v for k,v in zip(range(len(self.feats)),self.feats)}, inplace=True)\n","        df.reset_index(inplace=True)\n","        \n","        return df.pivot(idx_names[0],idx_names[1:],self.feats)\n","\n","print('[Class WTFeatureManager successfully loaded]')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[Class WTFeatureManager successfully loaded]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"unpu5rDal47N","colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","executionInfo":{"status":"ok","timestamp":1624640741395,"user_tz":-180,"elapsed":1138,"user":{"displayName":"עידן לביא","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGX4jNLFmOJ0Uy5vEXtc8TTrQ-ON3TkdZcPQdhPg=s64","userId":"12766125488901089854"}},"outputId":"d9d587ec-5d39-4526-d359-ce1aed915e10"},"source":["#@title <font color=\"\\#8FBC8F\">File loading utility code\n","\n","subject_index =  9#@param {type:'integer'}\n","DATA_DIR = r'/content/drive/MyDrive/Colab Notebooks/Project Domino/new Macros/'\n","subject_list = sorted([f for f in os.listdir(DATA_DIR) if 'sub' in f])\n","\n","subject_path = DATA_DIR + f'{subject_list[subject_index]}/'\n","subject_files = os.listdir(subject_path)\n","\n","if 'sub' not in locals() or sub != subject_list[subject_index]:\n","    sub = subject_list[subject_index] \n","\n","print(f'[Working on {sub}]')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[Working on sub-030]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YitG20gdokFe","cellView":"form","executionInfo":{"status":"ok","timestamp":1624640789435,"user_tz":-180,"elapsed":48044,"user":{"displayName":"עידן לביא","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGX4jNLFmOJ0Uy5vEXtc8TTrQ-ON3TkdZcPQdhPg=s64","userId":"12766125488901089854"}},"outputId":"2e1ae1c3-ade7-48df-941c-21c080a43c09"},"source":["#@title <font color=\"\\#8FBC8F\">Load Files\n","X_name = subject_path + f'{sub}_X.npy'\n","y_name = subject_path + f'{sub}_y.npy'\n","names_name = subject_path + f'{sub}_channel_names.npy'\n","\n","_X = np.load(X_name)\n","_y = np.load(y_name)\n","ch_names = np.load(names_name)\n","print(f'[Loaded X, y and channel names data succesfully]')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[Loaded X, y and channel names data succesfully]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q32H34a43i_3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624640994978,"user_tz":-180,"elapsed":116301,"user":{"displayName":"עידן לביא","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGX4jNLFmOJ0Uy5vEXtc8TTrQ-ON3TkdZcPQdhPg=s64","userId":"12766125488901089854"}},"outputId":"1a72964f-008a-4e56-d007-c75d77f3ac07"},"source":["#@title <font color=\"\\#8FBC8F\">WT Feature Extraction\n","\n","wtfm = WTFeatureManager(_X, ch_names)\n","\n","print(f'[Extracting {wtfm.feats} from each bin]\\n')\n","X = wtfm.as_dataframe()\n","y = pd.DataFrame(_y, columns=['label'])\n","\n","print(f'\\n[X and y loaded successfully]')\n","\n","del _X, _y"],"execution_count":10,"outputs":[{"output_type":"stream","text":["\rEpoch::   0%|          | 0/86 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Extracting ['min', 'max', 'mean', 'std', 'median'] from each bin]\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch:: 100%|██████████| 86/86 [01:10<00:00,  1.22it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[Creating DataFrame]\n","\n","[X and y loaded successfully]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eaWdSrx7tOnL","colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","executionInfo":{"status":"ok","timestamp":1624640995351,"user_tz":-180,"elapsed":379,"user":{"displayName":"עידן לביא","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGX4jNLFmOJ0Uy5vEXtc8TTrQ-ON3TkdZcPQdhPg=s64","userId":"12766125488901089854"}},"outputId":"64ad862d-246c-497a-dc47-36cf581f7205"},"source":["#@title <font color='darkgreen'>Pickle X and y - Utility\n","import datetime as dt\n","\n","now = (str(dt.datetime.now())[:-7]).replace(' ', '_')\n","print(f'[now is {now}]')\n","\n","pickle_path = f'/content/drive/My Drive/Colab Notebooks/Project Domino/Feature-Label matrices/{sub}/'\n","\n","if not os.path.isdir(pickle_path): os.mkdir(pickle_path)\n","os.mkdir(pickle_path+now)\n","\n","f_last = f'{sub}_last.txt'\n","with open(pickle_path+f_last, 'w') as f:\n","    f.write(now)\n","\n","\n","if 'label' in X.columns: X.drop('label', axis=1, inplace=True)\n","\n","X.to_pickle(pickle_path + now + '/X.pickle')\n","y.to_pickle(pickle_path + now + '/y.pickle')\n","print('[Pickled X and y feature-label files]')\n","\n","pd.DataFrame({'ch_names':ch_names}).to_csv(pickle_path + f'{sub} bipolar channel names.csv')\n","print('[Channel Names CSV saved]')\n","\n","with open(pickle_path + now + '/log.txt', 'w') as f:\n","    f.write(\n","        f'''\n","subject number:     {sub}\n","bin features:       {WTFeatureManager.feats}\n","bin time:           {WTFeatureManager.dt} [ms]\n","        '''\n","    )\n","\n","with open(pickle_path[:-1*(len(sub)+1)] + 'last.txt', 'w') as f:\n","    f.write(now + ' ' + sub)\n","\n","# del _X,_y, X, y"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[now is 2021-06-25_17:09:54]\n","[Pickled X and y feature-label files]\n","[Channel Names CSV saved]\n"],"name":"stdout"}]}]}